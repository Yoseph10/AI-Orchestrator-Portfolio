#APP USING ELASTICSERACH AND LLAMAINDEX

import os
import re
from typing import TypedDict, Annotated, Literal, List, Any, Dict

from dotenv import load_dotenv
from langchain_core.messages import AnyMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from llama_index.vector_stores.elasticsearch import ElasticsearchStore as le
from llama_index.core import VectorStoreIndex
from llama_index.core.vector_stores import (
    MetadataFilter,
    MetadataFilters,
    FilterOperator,
)
from llama_index.core import StorageContext

import sys
import locale

import smtplib
from email.message import EmailMessage
import streamlit as st


# Force Python to use UTF-8 for I/O streams
if sys.stdout.encoding != 'utf-8':
    sys.stdout = open(sys.stdout.fileno(), mode='w', encoding='utf-8', buffering=1)
if sys.stderr.encoding != 'utf-8':
    sys.stderr = open(sys.stderr.fileno(), mode='w', encoding='utf-8', buffering=1)
if sys.stdin.encoding != 'utf-8':
    sys.stdin = open(sys.stdin.fileno(), mode='r', encoding='utf-8', buffering=1)

# Ensure the system's default locale is also set to UTF-8
try:
    locale.setlocale(locale.LC_ALL, 'en_US.utf8')
except locale.Error:
    try:
        locale.setlocale(locale.LC_ALL, 'C.UTF-8')
    except locale.Error:
        pass


# --- 1. Configuraci贸n Inicial ---
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CV_PATH = "data_sources/cv.pdf"
SENDER_EMAIL = os.getenv("SENDER_EMAIL")
SENDER_PASSWORD = os.getenv("SENDER_PASSWORD")
CALENDLY_URL = os.getenv("CALENDLY_URL")
#Elastic credentials
es_elast = os.getenv("ES_PASSWORD")
es_url = os.getenv("ES_URL")


# --- 2. Herramientas del Agente (Tools) ---
@tool
def search_elastic(query: str, k: int = 4, filters: dict = None) -> str:
    """
    Busca informaci贸n relevante en el CV y otros documentos del portafolio,
    opcionalmente filtrando por metadatos como el 'file_name'.
    salo para responder preguntas sobre experiencia, proyectos, habilidades, y formaci贸n.
    """

    print(f"[Search Elastic] Iniciando b煤squeda con query: '{query}', k: {k}, filters: {filters}")

    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    vector_store = le(
            es_url=es_url,
            es_user="elastic",
            es_password=es_elast,
            index_name="ai_portafolio"
    )

    storage_context_read = StorageContext.from_defaults(vector_store=vector_store)

    print("[Search Elastic] Conexi贸n a Elasticsearch establecida.")

    try:
        index_read = VectorStoreIndex.from_vector_store(
            vector_store=vector_store,
            storage_context=storage_context_read, # Este es el par谩metro incorrecto
            embed_model=embeddings
        )
        print("隆El 铆ndice se carg贸 exitosamente!")

    except TypeError as e:
        print(f"ERROR: {e}")
        # El error te dir谩 algo como: "TypeError: VectorStoreIndex.from_vector_store() got an unexpected keyword argument 'storage_context'"
        # Esto te indica claramente que 'storage_context' no es un par谩metro v谩lido para esta funci贸n.
    except Exception as e:
        print(f"Ocurri贸 un error inesperado: {e}")

    print("[Search Elastic] VectorStoreIndex cargado correctamente.")


    if filters:
        for key, value in filters.items():
            # Si viene en formato {"eq": "cv.pdf"}, extraer el valor
            if isinstance(value, dict) and "eq" in value:
                value = value["eq"]

            print(f"Applying filter - Key: {key}, Value: {value}")

            llama_filters = MetadataFilters(
                filters=[
                    MetadataFilter(
                        key=key, value=value, operator=FilterOperator.TEXT_MATCH
                    )
                ]
            )

        print(f"[Search Elastic] Filtros construidos: {llama_filters}")
        retriever = index_read.as_retriever(filters=llama_filters, similarity_top_k=k)

        #results = retriever.retrieve(query)

        #print(results)

    else:
        retriever = index_read.as_retriever(search_kwargs={"k": k})

    results = retriever.retrieve(query)

    output = "\n\n".join([
        f"[{i+1}] {node.node.text.strip()}\nFuente: {node.node.metadata.get('source', 'N/A')}"
        for i, node in enumerate(results)
    ])

    return output if output else "No se encontraron resultados relevantes."


@tool
def send_cv(email_to: str) -> str:
    """
    Env铆a una copia del CV a la direcci贸n de correo electr贸nico proporcionada.
    Solo se debe usar cuando un reclutador pide expl铆citamente el CV.
    """
    if not os.path.exists(CV_PATH):
        return f"Error: El archivo del CV no se encuentra en '{CV_PATH}'."

    if not email_to:
        return "Error: No se proporcion贸 una direcci贸n de correo electr贸nico."

    try:
        # 1. Crear el objeto de mensaje
        msg = EmailMessage()
        msg["Subject"] = "CV de tu candidato | Yoseph Ayala"
        msg["From"] = SENDER_EMAIL
        msg["To"] = email_to
        msg.set_content("Adjunto mi Curriculum Vitae para tu revisi贸n. 隆Gracias!")

        # 2. Adjuntar el archivo CV
        with open(CV_PATH, "rb") as attachment:
            file_data = attachment.read()
            file_name = os.path.basename(CV_PATH)

        msg.add_attachment(file_data, maintype="application", subtype="pdf", filename=file_name)

        # 3. Conectarse y enviar el correo usando la misma l贸gica que funciona
        with smtplib.SMTP("smtp.gmail.com", 587) as smtp:
            smtp.starttls()
            smtp.login(SENDER_EMAIL, SENDER_PASSWORD)
            smtp.send_message(msg)

        return f"隆xito! El CV ha sido enviado a {email_to}."

    except smtplib.SMTPAuthenticationError:
        return "Error de autenticaci贸n. Por favor, revisa tu correo y contrase帽a de aplicaci贸n en el archivo .env."
    except Exception as e:
        return f"Error al enviar el correo: {e}"

@tool
def schedule_call(nombre: str, email: str, asunto: str) -> str:
    """
    Proporciona un enlace a Calendly para que un usuario pueda agendar una llamada.
    Solo se debe usar cuando un usuario solicita expl铆citamente agendar una reunion.
    """
    if not CALENDLY_URL:
        return "Error: La URL de Calendly no est谩 configurada. Por favor, contacta al desarrollador."

    # Aqu铆 puedes personalizar el mensaje para el usuario
    message = (
        f"Claro, {nombre}. Para agendar una reuni贸n, por favor usa mi enlace de Calendly. "
        "Ah铆 podr谩s ver mis horarios disponibles y elegir el que mejor te convenga. "
        f"El enlace es: {CALENDLY_URL}"
    )

    return message

# --- Definici贸n de conjuntos de herramientas por rol ---
tools_reclutador = [search_elastic, send_cv]
tools_cliente = [search_elastic, schedule_call]
tools_alumno = [search_elastic]
tools_otro = [search_elastic, schedule_call]

TOOLS_BY_ROLE = {
    "reclutador": tools_reclutador,
    "cliente": tools_cliente,
    "alumno": tools_alumno,
    "otro": tools_otro,
    "pregunta": tools_otro,
}

# --- Descripciones amigables de las herramientas ---
TOOL_DESCRIPTIONS = {
    "reclutador": "Como reclutador, puedes preguntarme sobre la **experiencia, habilidades y proyectos** del candidato. Tambi茅n puedo **enviarte su CV** por correo si lo necesitas.",
    "cliente": "Como cliente, puedo responder a tus preguntas, ayudarte a entender c贸mo puedo solucionar tus problemas y **agendar una llamada** si est谩s listo para discutir un proyecto.",
    "alumno": "Como estudiante, puedes preguntarme sobre **cualquier tema en el CV** relacionado con cursos, proyectos o formaci贸n para inspirarte.",
    "otro": "Te doy la bienvenida. Puedes preguntarme sobre la **experiencia profesional, habilidades o proyectos** del portafolio. Tambi茅n puedo **agendar una llamada** para ti.",
}

# --- 3. Estado del Grafo (Graph State) ---
class GraphState(TypedDict):
    messages: Annotated[list[AnyMessage], add_messages]
    user_type: Literal["reclutador", "alumno", "cliente", "pregunta", "otro"]
    last_user_type: str # Nuevo campo para rastrear el tipo de usuario anterior


# --- 4. Nodos del Grafo (Graph Nodes) ---
def classifier_node(state: GraphState):
    conversation_history = state["messages"]
    formatted_history = "\n".join([f"{msg.type}: {msg.content}" for msg in conversation_history])
    llm = ChatOpenAI(model="gpt-4o", temperature=0.0)

    prompt = f"""
    Eres un clasificador de intenci贸n. Analiza la CONVERSACIN COMPLETA para determinar la intenci贸n del LTIMO mensaje del usuario.
    Responde SOLO con una de estas categor铆as: 'reclutador', 'alumno', 'cliente', 'pregunta', 'otro'.
    Si el 煤ltimo mensaje es una pregunta general o no define un rol claro, usa 'pregunta'.

    CONVERSACIN:
    {formatted_history}

    Basado en la conversaci贸n, 驴cu谩l es la categor铆a del 煤ltimo mensaje 'human'?
    Categor铆a:
    """

    classification = llm.invoke(prompt).content.strip().lower()
    cleaned_classification = re.sub(r'[^a-z]', '', classification)
    if cleaned_classification not in TOOLS_BY_ROLE.keys():
        cleaned_classification = "otro"

    print(f"[Classifier] Intenci贸n detectada: {cleaned_classification}")
    return {"user_type": cleaned_classification}


# Modificaci贸n del agent_node
def agent_node(state: GraphState):
    user_type = state.get("user_type", "otro")
    last_user_type = state.get("last_user_type", None)

    # Generamos el mensaje de bienvenida y el prompt del sistema
    initial_message = ""
    if user_type != last_user_type:
        initial_message = f"隆Perfecto! {TOOL_DESCRIPTIONS.get(user_type, '')}\n"

    # --- Se agrega la l贸gica de filtros aqu铆 ---
    filter_logic = ""
    if user_type == "reclutador":
        filter_logic = (
            "Para responder preguntas sobre la experiencia laboral y el curriculum del candidato, utiliza la herramienta `search_elastic`\
            .Aseg煤rate de incluir el filtro `filters={'file_name': 'cv.pdf'}` en la llamada a la herramienta para buscar solo en el CV."
        )
    elif user_type in ["cliente", "alumno"]:
        filter_logic = (
            "Para responder preguntas sobre proyectos o formaci贸n acad茅mica, usa la herramienta `search_elastic`. "
            "Siempre incluye el filtro `filters={'file_name': 'Portafolio Extendido.pdf'}` en la llamada a la herramienta para obtener resultados detallados."
        )
    else:
        # No se aplica ning煤n filtro para 'otro' o 'pregunta'
        filter_logic = (
            "Para este tipo de usuario, utiliza la herramienta `search_elastic` sin ning煤n filtro para buscar en todos los documentos disponibles."
        )

    system_prompts = {
        "reclutador": f"""Eres un asistente profesional que representa al due帽o de este portafolio. Es decir, eres Yoseph Ayala el consultor en IA y Data Science.
            Tu objetivo es destacar su experiencia y habilidades para conseguir un empleo. {filter_logic}.
            Solo usa la herramienta de enviar CV (`send_cv`) si el usuario lo pide expl铆citamente.
            Si no cuentas con  la informaci贸n, responde directamente que no cuentas con la informaci贸n. S茅 amable y profesional.""",
        "cliente": f"""Eres un asistente comercial y consultor que actua como si fuese Yoseph Ayala. Tu objetivo es entender las necesidades del cliente,
            explicar c贸mo los servicios o productos pueden ayudarle, y facilitar el contacto o agendar una reuni贸n. S茅 proactivo y servicial.
            {filter_logic} para vender los servicios del portafolio. Utiliza la herramienta de agendar llamada (`schedule_call`) cuando el usuario lo solicite.
            Si no cuentas con  la informaci贸n, responde directamente que no cuentas con la informaci贸n. S茅 amable y profesional.""",
        "alumno": f"""Eres Yoseph Ayala, un profesor. Tu objetivo es resolver dudas sobre cursos o formaci贸n que ofreces. {filter_logic}.
            Si no cuentas con  la informaci贸n, responde directamente que no cuentas con la informaci贸n. S茅 amable y profesiona""",
        "otro": f"""Eres un asistente conversacional general que actua como Yoseph Ayala. Responde de forma amable y profesional. {filter_logic}.
            Si la pregunta no es sobre el portafolio, responde de forma conversacional.
            La herramienta de agendar llamada (`schedule_call`) solo debe usarse si el usuario lo pide.
            Si no cuentas con  la informaci贸n, responde directamente que no cuentas con la informaci贸n. S茅 amable y profesional.""",
        "pregunta": f"""Eres un asistente conversacional que actua como Yoseph Ayala. Tu objetivo es responder la pregunta del usuario. {filter_logic}.
            Si no cuentas con  la informaci贸n, responde directamente que no cuentas con la informaci贸n. S茅 amable y profesional.""",
    }

    prompt_content = system_prompts.get(user_type, system_prompts["otro"])
    system_message = SystemMessage(content=prompt_content)

    tools_for_agent = TOOLS_BY_ROLE.get(user_type, tools_otro)
    llm = ChatOpenAI(model="gpt-4o", temperature=0.2)
    llm_with_tools = llm.bind_tools(tools_for_agent)

    # El LLM necesita ver el historial completo, incluyendo el mensaje de bienvenida
    # si se ha generado.
    messages_for_llm = [system_message] + state["messages"]

    response = llm_with_tools.invoke(messages_for_llm)

    # Si hay un mensaje de bienvenida, se a帽ade antes de la respuesta del LLM
    final_messages = []
    if initial_message:
        final_messages.append(AIMessage(content=initial_message))

    final_messages.append(response)

    # Actualizamos el estado con los nuevos mensajes y el user_type
    return {"messages": final_messages, "last_user_type": user_type}

# A este c贸digo se le debe a帽adir tambi茅n un ajuste en el `clarification_node`
def clarification_node(state: GraphState):
    # La primera vez que el usuario llega a este nodo, el last_user_type estar谩 vac铆o.
    # As铆, la siguiente vez que entre al agent_node, se imprimir谩 el mensaje de bienvenida
    return {"messages": [AIMessage(content="隆Hola! Para poder ayudarte mejor, 驴me podr铆as decir si eres un reclutador, un posible cliente, un alumno o tienes otra consulta?")], "last_user_type": "pregunta"}

# --- 5. L贸gica de Enrutamiento (Router) ---
def router(state: GraphState) -> Literal["agent", "clarification"]:
    # Obtener la clasificaci贸n actual y la anterior (si existe)
    user_type = state["user_type"]
    last_user_type = state.get("last_user_type")

    # Si ya se ha establecido un rol y el clasificador no lo cambi贸 a "pregunta",
    # entonces continuamos con el agente sin volver a preguntar.
    if last_user_type and user_type == "pregunta" and last_user_type != "pregunta":
        # Se asume que la nueva pregunta es parte del mismo rol, a menos que se indique lo contrario.
        # Volvemos a asignar el user_type anterior para no perder el contexto.
        state["user_type"] = last_user_type
        print(f"[Router] Manteniendo rol '{last_user_type}'.")
        return "agent"

    # Si el usuario es 'pregunta' y es la primera vez que se interact煤a, se va a aclaraci贸n.
    if user_type == "pregunta" and not last_user_type:
        print("[Router] No se ha definido un rol. Yendo a aclaraci贸n.")
        return "clarification"

    # Si la clasificaci贸n es una de las opciones v谩lidas, va al agente.
    print(f"[Router] Clasificaci贸n exitosa: '{user_type}'. Yendo a agente.")
    return "agent"


# --- 6. Construcci贸n del Grafo ---
all_tools = tools_reclutador + tools_cliente + tools_alumno + tools_otro
tool_node = ToolNode(all_tools)

builder = StateGraph(GraphState)
builder.add_node("classifier", classifier_node)
builder.add_node("agent", agent_node)
builder.add_node("tools", tool_node)
builder.add_node("clarification", clarification_node)
builder.set_entry_point("classifier")

builder.add_conditional_edges(
    "classifier",
    router,
    {"agent": "agent", "clarification": "clarification"}
)

def should_continue(state: GraphState) -> Literal["tools", "__end__"]:
    last_message = state["messages"][-1]
    return "tools" if last_message.tool_calls else "__end__"

builder.add_conditional_edges("agent", should_continue)
builder.add_edge("tools", "agent")
builder.add_edge("clarification", END)


# --- 7. Compilaci贸n y Configuraci贸n de la Memoria ---

# Almacena MemorySaver en st.session_state para que persista a trav茅s de recargas.
if "memory_saver" not in st.session_state:
    st.session_state["memory_saver"] = MemorySaver()

# Usa la instancia de MemorySaver almacenada en session_state
memory = st.session_state["memory_saver"]

graph = builder.compile(checkpointer=memory)


# ---------- 9. Interfaz Streamlit ----------
st.set_page_config(page_title="Portafolio Inteligente", page_icon="")
st.title(" Multiagente de IA")

def main():

    if "history" not in st.session_state:
        st.session_state["history"] = []

    for mensaje in st.session_state["history"]:
        with st.chat_message(mensaje["role"]):
            st.markdown(mensaje["content"])

    user_input = st.chat_input("Escribe algo...")

    if user_input:
        st.session_state["history"].append({"role": "user", "content": user_input})

        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            output = ""
            try:
                config = {"configurable": {"thread_id": "test_id"}}

                all_messages = []

                for paso in graph.stream({"messages": [HumanMessage(content=user_input)]}, config, stream_mode="values"):
                    all_messages.extend(paso["messages"])

                if all_messages:
                    # El 煤ltimo mensaje de 'all_messages' contendr谩 la respuesta final del asistente.
                    final_assistant_message = all_messages[-1].content
                    st.markdown(final_assistant_message)
                    output = final_assistant_message
                else:
                    st.markdown("No se gener贸 ninguna respuesta.")

            except Exception as e:
                st.error(f"Error: {e}")
                output = f"Error: {e}"

        st.session_state["history"].append({"role": "assistant", "content": output})

if __name__ == "__main__":
    main()
